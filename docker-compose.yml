version: '3.8'

services:
  vllm-server:
    build: .
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - .:/app
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    command: >
      bash -c "
      python3 download_model.py &&
      python3 -m vllm.entrypoints.openai.api_server
      --model /app/models/QVikhr-3-1.7B-Instruction-noreasoning.Q4_K_M
      --host 0.0.0.0
      --port 8000
      --tensor-parallel-size 1
      --max-model-len 4096
      --dtype float16"

  word-segmentation:
    build: .
    depends_on:
      - vllm-server
    volumes:
      - .:/app
    command: ["python3", "space_restoration_solution.py"]
    environment:
      - VLLM_API_URL=http://vllm-server:8000